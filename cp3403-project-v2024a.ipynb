{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5793796,"sourceType":"datasetVersion","datasetId":199387}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-12T04:11:20.422178Z","iopub.execute_input":"2024-03-12T04:11:20.422578Z","iopub.status.idle":"2024-03-12T04:11:20.429297Z","shell.execute_reply.started":"2024-03-12T04:11:20.422547Z","shell.execute_reply":"2024-03-12T04:11:20.427668Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Your team\n* Joshua Finch\n* Kyle Ormonde\n* Ingrid Moe","metadata":{}},{"cell_type":"markdown","source":"# Task 1: Dataset\nThe first step is to find your own domain-specific dataset for your data mining project. The dataset should be complex enough so that it is not straightforward to find patterns with simple calculations (impossible without preprocessing and data mining approaches). There is no limit in size for the dataset, but typically a good sized data for mining is around 100k-100M. Minimum of 100k samples/rows and minimum of 100 attributes/columns. \n\nIt could have thousands/millions rows (or columns or sometimes both rows/columns). A good data typically contains various types of data (numerical, nominal, ordinal, Boolean etc) with some errors (missing or dirty values etc) in the data. The dataset could be text data, tabular formatted data, georeferenced data. See possible data sources: Kaggle repository (https://www.kaggle.com/datasets).","metadata":{}},{"cell_type":"code","source":"# todo: import dataset(s) into pandas and print samples.\nfpath = '/kaggle/input/us-accidents/US_Accidents_March23.csv'\n\n#~~~ full data run ~~~\n# df = pd.read_csv(fpath, header=0)\n\n#~~~ no null lat/long ~~~\ndf = pd.read_csv(fpath, header=0, na_values=['nan']).dropna()\n\n#~~~ random % of rows ~~~\ndf10 = df.sample(frac=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T04:11:24.031473Z","iopub.execute_input":"2024-03-12T04:11:24.031889Z","iopub.status.idle":"2024-03-12T04:14:47.471362Z","shell.execute_reply.started":"2024-03-12T04:11:24.031855Z","shell.execute_reply":"2024-03-12T04:14:47.469274Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Print sample rows\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-12T04:22:54.683694Z","iopub.execute_input":"2024-03-12T04:22:54.684199Z","iopub.status.idle":"2024-03-12T04:22:54.717179Z","shell.execute_reply.started":"2024-03-12T04:22:54.684162Z","shell.execute_reply":"2024-03-12T04:22:54.715953Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                ID   Source  Severity           Start_Time  \\\n3402762  A-3412645  Source1         3  2016-02-08 00:37:08   \n3402767  A-3412650  Source1         3  2016-02-08 07:53:43   \n3402771  A-3412654  Source1         2  2016-02-08 11:51:46   \n3402773  A-3412656  Source1         2  2016-02-08 15:16:43   \n3402774  A-3412657  Source1         2  2016-02-08 15:43:50   \n\n                    End_Time  Start_Lat  Start_Lng    End_Lat    End_Lng  \\\n3402762  2016-02-08 06:37:08  40.108910 -83.092860  40.112060 -83.031870   \n3402767  2016-02-08 13:53:43  39.172393 -84.492792  39.170476 -84.501798   \n3402771  2016-02-08 17:51:46  41.375310 -81.820170  41.367860 -81.821740   \n3402773  2016-02-08 21:16:43  40.109310 -82.968490  40.110780 -82.984000   \n3402774  2016-02-08 21:43:50  39.192880 -84.477230  39.196150 -84.473350   \n\n         Distance(mi)  ... Roundabout Station   Stop Traffic_Calming  \\\n3402762         3.230  ...      False   False  False           False   \n3402767         0.500  ...      False   False  False           False   \n3402771         0.521  ...      False   False  False           False   \n3402773         0.826  ...      False   False  False           False   \n3402774         0.307  ...      False   False  False           False   \n\n        Traffic_Signal Turning_Loop Sunrise_Sunset Civil_Twilight  \\\n3402762          False        False          Night          Night   \n3402767          False        False            Day            Day   \n3402771          False        False            Day            Day   \n3402773          False        False            Day            Day   \n3402774          False        False            Day            Day   \n\n        Nautical_Twilight Astronomical_Twilight  \n3402762             Night                 Night  \n3402767               Day                   Day  \n3402771               Day                   Day  \n3402773               Day                   Day  \n3402774               Day                   Day  \n\n[5 rows x 46 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Source</th>\n      <th>Severity</th>\n      <th>Start_Time</th>\n      <th>End_Time</th>\n      <th>Start_Lat</th>\n      <th>Start_Lng</th>\n      <th>End_Lat</th>\n      <th>End_Lng</th>\n      <th>Distance(mi)</th>\n      <th>...</th>\n      <th>Roundabout</th>\n      <th>Station</th>\n      <th>Stop</th>\n      <th>Traffic_Calming</th>\n      <th>Traffic_Signal</th>\n      <th>Turning_Loop</th>\n      <th>Sunrise_Sunset</th>\n      <th>Civil_Twilight</th>\n      <th>Nautical_Twilight</th>\n      <th>Astronomical_Twilight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3402762</th>\n      <td>A-3412645</td>\n      <td>Source1</td>\n      <td>3</td>\n      <td>2016-02-08 00:37:08</td>\n      <td>2016-02-08 06:37:08</td>\n      <td>40.108910</td>\n      <td>-83.092860</td>\n      <td>40.112060</td>\n      <td>-83.031870</td>\n      <td>3.230</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Night</td>\n      <td>Night</td>\n      <td>Night</td>\n      <td>Night</td>\n    </tr>\n    <tr>\n      <th>3402767</th>\n      <td>A-3412650</td>\n      <td>Source1</td>\n      <td>3</td>\n      <td>2016-02-08 07:53:43</td>\n      <td>2016-02-08 13:53:43</td>\n      <td>39.172393</td>\n      <td>-84.492792</td>\n      <td>39.170476</td>\n      <td>-84.501798</td>\n      <td>0.500</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Day</td>\n      <td>Day</td>\n      <td>Day</td>\n      <td>Day</td>\n    </tr>\n    <tr>\n      <th>3402771</th>\n      <td>A-3412654</td>\n      <td>Source1</td>\n      <td>2</td>\n      <td>2016-02-08 11:51:46</td>\n      <td>2016-02-08 17:51:46</td>\n      <td>41.375310</td>\n      <td>-81.820170</td>\n      <td>41.367860</td>\n      <td>-81.821740</td>\n      <td>0.521</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Day</td>\n      <td>Day</td>\n      <td>Day</td>\n      <td>Day</td>\n    </tr>\n    <tr>\n      <th>3402773</th>\n      <td>A-3412656</td>\n      <td>Source1</td>\n      <td>2</td>\n      <td>2016-02-08 15:16:43</td>\n      <td>2016-02-08 21:16:43</td>\n      <td>40.109310</td>\n      <td>-82.968490</td>\n      <td>40.110780</td>\n      <td>-82.984000</td>\n      <td>0.826</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Day</td>\n      <td>Day</td>\n      <td>Day</td>\n      <td>Day</td>\n    </tr>\n    <tr>\n      <th>3402774</th>\n      <td>A-3412657</td>\n      <td>Source1</td>\n      <td>2</td>\n      <td>2016-02-08 15:43:50</td>\n      <td>2016-02-08 21:43:50</td>\n      <td>39.192880</td>\n      <td>-84.477230</td>\n      <td>39.196150</td>\n      <td>-84.473350</td>\n      <td>0.307</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Day</td>\n      <td>Day</td>\n      <td>Day</td>\n      <td>Day</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 46 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from pandas.api.types import is_numeric_dtype\n\nfor col in df.columns:\n    if is_numeric_dtype(df[col]) == False:\n        print(f\"Column: {col}\")\n        print(\"-\" * 30)  # Separator\n\n        # Get the value counts and sort by count (descending)\n        value_counts = df[col].value_counts().sort_values(ascending=False)\n\n        # Print the top 10 categories (you can adjust the number as needed)\n        for category, count in value_counts.head(5).items():\n            print(f\"{category}: {count}\")\n\n        print(\"\\n\")  # Add a blank line between columns","metadata":{"execution":{"iopub.status.busy":"2024-03-12T04:23:48.115338Z","iopub.execute_input":"2024-03-12T04:23:48.115698Z","iopub.status.idle":"2024-03-12T04:24:24.316999Z","shell.execute_reply.started":"2024-03-12T04:23:48.115667Z","shell.execute_reply":"2024-03-12T04:24:24.315820Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Column: ID\n------------------------------\nA-3412645: 1\nA-3412670: 1\nA-3412759: 1\nA-3412696: 1\nA-3412654: 1\n\n\nColumn: Source\n------------------------------\nSource1: 3554549\n\n\nColumn: Start_Time\n------------------------------\n2021-01-26 16:16:13: 225\n2021-01-26 16:17:33: 156\n2021-02-16 06:42:43: 129\n2021-11-21 18:37:51: 108\n2020-12-16 13:53:25: 96\n\n\nColumn: End_Time\n------------------------------\n2021-11-22 08:00:00: 112\n2019-10-26 09:14:51: 49\n2020-02-14 00:00:00: 46\n2020-02-12 00:00:00: 42\n2020-01-25 00:00:00: 41\n\n\nColumn: Description\n------------------------------\nA crash has occurred causing no to minimum delays. Use caution.: 9211\nAccident: 6210\nAn unconfirmed report of a crash has been received. Use caution.: 3612\nA crash has occurred use caution.: 2833\nA crash has occurred with minimal delay to traffic. Prepare to slow or move over for worker safety.: 2585\n\n\nColumn: Street\n------------------------------\nI-5 N: 36694\nI-95 N: 36062\nI-95 S: 35293\nI-5 S: 31589\nI-10 E: 24387\n\n\nColumn: City\n------------------------------\nMiami: 142575\nLos Angeles: 79444\nOrlando: 74911\nDallas: 50074\nHouston: 46197\n\n\nColumn: County\n------------------------------\nLos Angeles: 230384\nMiami-Dade: 194263\nOrange: 147809\nSan Bernardino: 63643\nDallas: 59621\n\n\nColumn: State\n------------------------------\nCA: 880453\nFL: 529393\nTX: 178750\nVA: 176331\nNY: 168004\n\n\nColumn: Zipcode\n------------------------------\n33186: 6818\n91761: 6815\n92407: 5499\n92507: 5116\n32819: 5020\n\n\nColumn: Country\n------------------------------\nUS: 3554549\n\n\nColumn: Timezone\n------------------------------\nUS/Eastern: 1691989\nUS/Pacific: 1057841\nUS/Central: 605066\nUS/Mountain: 199653\n\n\nColumn: Airport_Code\n------------------------------\nKMIA: 61685\nKCQT: 60400\nKOPF: 53505\nKORL: 50910\nKTMB: 48170\n\n\nColumn: Weather_Timestamp\n------------------------------\n2022-03-13 01:53:00: 1116\n2021-01-26 15:53:00: 619\n2022-05-13 16:53:00: 525\n2022-05-17 15:53:00: 475\n2022-04-29 14:53:00: 463\n\n\nColumn: Wind_Direction\n------------------------------\nCALM: 618197\nS: 269311\nW: 261895\nN: 199179\nE: 190121\n\n\nColumn: Weather_Condition\n------------------------------\nFair: 1697787\nCloudy: 524654\nMostly Cloudy: 457519\nPartly Cloudy: 311743\nLight Rain: 164310\n\n\nColumn: Sunrise_Sunset\n------------------------------\nDay: 2308810\nNight: 1245739\n\n\nColumn: Civil_Twilight\n------------------------------\nDay: 2453902\nNight: 1100647\n\n\nColumn: Nautical_Twilight\n------------------------------\nDay: 2618743\nNight: 935806\n\n\nColumn: Astronomical_Twilight\n------------------------------\nDay: 2755457\nNight: 799092\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"*Say something meaningful about your dataset. For example: Why did you select it? Is there anything interesting or special about it? What do or did hope to learn from it?*\n\n# Data Set Overview\n## What is it?\nThis dataset is a countrywide car accident dataset that covers 49 states of the USA from February 2016 to March 2023 containing 7.7 million records.\n\n## Points of Interest:\nThe dataset contains a broad spectrum of information regarding all aspects of car accidents such as length of the road affected by the accident, duration, time, and severity. It also contains highly detailed weather data such as temperature, wind direction, wind speed, and precipitation. Additionally, the data set categorises different configurations of roads such as if they contain a give-way, a railway, roundabouts, junctions, etc.\n\n## Learning Goals:\nThe owner of this dataset has hopes that it can be used for a vast amount applications such as real-time accident prediction, studying accident hotspot locations, casualty analysis and potentially even identifying cause and effect rules to predict accidents.(Sobhan Moosavi, January 2021)\nWe hope to be able to identify which combination of driving conditions, outside of the obvious ones, are more likely to result in an accident in order to know what to be more aware of.","metadata":{}},{"cell_type":"markdown","source":"# Task 2: business scenarios\n*List one or more possible questions you would like to investigate using your dataset. You may start this project with one set of questions but (after exploring the dataset) finish with a new set of questions and answers.*\n\n## Accident Analysis\n\n### Time\n1. **Annual**: When is the most and least likely times for an accident to occur per year?\n2. **Monthly**: When is the most and least likely times for an accident to occur per month?\n3. **Daily**: When is the most and least likely times for an accident to occur per 24 hours?\n\n### Location\n1. **County**: Where is the most likely place for accidents to occur per county?\n2. **State**: Where is the most likely place for accidents to occur per state?\n3. **City**: Where is the most likely place for accidents to occur per city?\n\n### Environmental Conditions\n1. **Weather**: What are the most and least common crash causing environmental conditions (precipitation, wind)?\n2. **Conditions**: What are the most and least common crash causing driving conditions (visibility)?\n\n### Infrastructure\n1. What are the most and least common crash causing road infrastructures (roundabouts, traffic lights, etc)?","metadata":{}},{"cell_type":"code","source":"# some python code and results to support your business cases\n df.describe(include='all')  # see prac-1. \n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T02:19:50.462003Z","iopub.status.idle":"2024-03-12T02:19:50.462545Z","shell.execute_reply.started":"2024-03-12T02:19:50.462307Z","shell.execute_reply":"2024-03-12T02:19:50.462330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NOTE! This is a data-based project. Make sure your comments are based on printed code outputs and/or graphs.","metadata":{}},{"cell_type":"markdown","source":"# Task-3: preprocessing\nSee prac-2. Apply one or more preprocessing techniques","metadata":{}},{"cell_type":"code","source":"# TODO: python code with outputs\n# Add some comments to explain what and why you did.\n# NOTE! unless you have a very good reason, do not drop rows nor columns\ndata = df.copy()\n\nprint('The dataset has {} rows and {} columns'.format(data.shape[0], data.shape[1]))\nprint(data.describe())","metadata":{"execution":{"iopub.status.busy":"2024-02-27T01:20:56.478150Z","iopub.execute_input":"2024-02-27T01:20:56.479653Z","iopub.status.idle":"2024-02-27T01:24:00.543050Z","shell.execute_reply.started":"2024-02-27T01:20:56.479588Z","shell.execute_reply":"2024-02-27T01:24:00.541731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes.value_counts()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T01:47:05.252319Z","iopub.execute_input":"2024-02-27T01:47:05.252908Z","iopub.status.idle":"2024-02-27T01:47:05.266953Z","shell.execute_reply.started":"2024-02-27T01:47:05.252851Z","shell.execute_reply":"2024-02-27T01:47:05.265202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf['ID'] = pd.to_numeric(df['ID'], errors='coerce') #convert Long attribute to numeric\n\n\nprint(df.dtypes.value_counts()) #HELP","metadata":{"execution":{"iopub.status.busy":"2024-02-27T01:51:16.671748Z","iopub.execute_input":"2024-02-27T01:51:16.672253Z","iopub.status.idle":"2024-02-27T01:51:16.783384Z","shell.execute_reply.started":"2024-02-27T01:51:16.672216Z","shell.execute_reply":"2024-02-27T01:51:16.781303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_attributes = df.columns[df.dtypes != \"object\"]\ncategorical_attributes = df.columns[df.dtypes == \"object\"]\n\nprint(numeric_attributes)\nprint(categorical_attributes) # what am i doing wrong? ","metadata":{"execution":{"iopub.status.busy":"2024-02-27T01:45:09.240808Z","iopub.execute_input":"2024-02-27T01:45:09.241353Z","iopub.status.idle":"2024-02-27T01:45:09.251500Z","shell.execute_reply.started":"2024-02-27T01:45:09.241313Z","shell.execute_reply":"2024-02-27T01:45:09.250201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task-4: ARM","metadata":{}},{"cell_type":"code","source":"# Apply one or more ARM techiques, see prac-3-ARM\n# Report your results based on your code output","metadata":{"execution":{"iopub.status.busy":"2024-01-30T05:44:11.558329Z","iopub.execute_input":"2024-01-30T05:44:11.558754Z","iopub.status.idle":"2024-01-30T05:44:11.563357Z","shell.execute_reply.started":"2024-01-30T05:44:11.558722Z","shell.execute_reply":"2024-01-30T05:44:11.562476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task-5: Classification","metadata":{}},{"cell_type":"code","source":"# apply one or more classification methods, see pracs-4 and 5\n# Report your results based on your code output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task-6: Clustering","metadata":{}},{"cell_type":"code","source":"# apply one or more clustering methods, see pracs-6 and 7\n# Report your results based on your code output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task-7: Project specific and final results","metadata":{}},{"cell_type":"code","source":"# The preceding tasks may or may not produce interesting results. They are mandatory exploration tasks.\n# In this section you need to focus on anything interesting you found so far, which is specific to your data. \n# Some additional code and output may be needed here to make any final conclusions.","metadata":{},"execution_count":null,"outputs":[]}]}