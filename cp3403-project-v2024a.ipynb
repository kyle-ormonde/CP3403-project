{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Your team\n* Add your team member names here\n* name 1\n* name 2, etc","metadata":{}},{"cell_type":"markdown","source":"# Task 1: Dataset","metadata":{}},{"cell_type":"markdown","source":"The first step is to find your own domain-specific dataset for your data mining project. The dataset should be complex enough so that it is not straightforward to find patterns with simple calculations (impossible without preprocessing and data mining approaches). There is no limit in size for the dataset, but typically a good sized data for mining is around 100k-100M. Minimum of 100k samples/rows and minimum of 100 attributes/columns. \n\nIt could have thousands/millions rows (or columns or sometimes both rows/columns). A good data typically contains various types of data (numerical, nominal, ordinal, Boolean etc) with some errors (missing or dirty values etc) in the data. The dataset could be text data, tabular formatted data, georeferenced data. See possible data sources: Kaggle repository (https://www.kaggle.com/datasets).","metadata":{}},{"cell_type":"code","source":"# todo: import dataset(s) into pandas and print samples.\n# fpath = '/kaggle/input/cp3403-mushroom/mushroom.csv'\n# df = pd.read_csv(fpath, header=None)\n# Print sample rows\n# df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Say something meaningful about your dataset. For example: Why did you select it? Is there anything interesting or special about it? What do or did hope to learn from it?","metadata":{}},{"cell_type":"markdown","source":"# Task 2: business scenarios","metadata":{}},{"cell_type":"markdown","source":"List one or more possible questions you would like to investigate using your dataset. You may start this project with one set of questions but (after exploring the dataset) finish with a new set of questions and answers.","metadata":{}},{"cell_type":"code","source":"# some python code and results to support your business cases\n# df.describe(include='all')  # see prac-1. ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NOTE! This is a data-based project. Make sure your comments are based on printed code outputs and/or graphs.","metadata":{}},{"cell_type":"markdown","source":"# Tast-3: preprocessing","metadata":{}},{"cell_type":"markdown","source":"See prac-2. Apply one or more preprocessing techniques","metadata":{}},{"cell_type":"code","source":"# TODO: python code with outputs\n# Add some comments to explain what and why you did.\n# NOTE! unless you have a very good reason, do not drop rows nor columns","metadata":{"execution":{"iopub.status.busy":"2024-01-30T05:41:34.937446Z","iopub.execute_input":"2024-01-30T05:41:34.937772Z","iopub.status.idle":"2024-01-30T05:41:34.96475Z","shell.execute_reply.started":"2024-01-30T05:41:34.937746Z","shell.execute_reply":"2024-01-30T05:41:34.964062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task-4: ARM","metadata":{}},{"cell_type":"code","source":"# Apply one or more ARM techiques, see prac-3-ARM\n# Report your results based on your code output","metadata":{"execution":{"iopub.status.busy":"2024-01-30T05:44:11.558329Z","iopub.execute_input":"2024-01-30T05:44:11.558754Z","iopub.status.idle":"2024-01-30T05:44:11.563357Z","shell.execute_reply.started":"2024-01-30T05:44:11.558722Z","shell.execute_reply":"2024-01-30T05:44:11.562476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task-5: Classification","metadata":{}},{"cell_type":"code","source":"# apply one or more classification methods, see pracs-4 and 5\n# Report your results based on your code output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task-6: Clustering","metadata":{}},{"cell_type":"code","source":"# apply one or more clustering methods, see pracs-6 and 7\n# Report your results based on your code output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task-7: Project specific and final results","metadata":{}},{"cell_type":"code","source":"# The preceding tasks may or may not produce interesting results. They are mandatory exploration tasks.\n# In this section you need to focus on anything interesting you found so far, which is specific to your data. \n# Some additional code and output may be needed here to make any final conclusions.","metadata":{},"execution_count":null,"outputs":[]}]}